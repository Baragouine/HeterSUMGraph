{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HeterSUMGraphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.create_graph_dataset import create_graph_dataset\n",
    "from utils.GloveMgr import GloveMgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse args if script mode\n",
    "parser = argparse.ArgumentParser(description='extractive summary')\n",
    "\n",
    "parser.add_argument('-is_graphic',type=int,default=1,choices=[0,1])\n",
    "parser.add_argument('-gpu_num',type=int,default=0)\n",
    "parser.add_argument('-batch_size',type=int,default=32)\n",
    "parser.add_argument('-epochs',type=int,default=100)\n",
    "parser.add_argument('-dataset',type=str,default=\"data/nyt_corpus_LDC2008T19_50.json\")\n",
    "\n",
    "args = None\n",
    "\n",
    "if is_notebook():\n",
    "    args = parser.parse_args(\"\")\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse:\n",
      "is_graphic: True\n",
      "cuda_num: 0\n",
      "epochs 100\n",
      "batch_size 32\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "is_graphic = args.is_graphic != 0\n",
    "cuda_num = args.gpu_num\n",
    "embed_name = \"glove.6B.300\"\n",
    "\n",
    "# hyper-parameters\n",
    "vocab_size = 50000\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "learning_rate = 5e-4\n",
    "early_stopping = 3\n",
    "model_name = \"HeterSUMGraph\"\n",
    "sub_folder_name = \"model_name__{}__time__{}__embed_name__{}__lr__{}__batch_size__{}__vocab_size__{}__cuda_num__{}__early_stopping__{}\".format(model_name, time(), embed_name, learning_rate, batch_size, vocab_size, cuda_num, early_stopping)\n",
    "checkpoints_folder = \"./checkpoints/\" + sub_folder_name\n",
    "average_proportion_of_sentences_per_document = 0.2670278281534701\n",
    "average_number_of_sentences_per_document = 6.061850780738518\n",
    "\n",
    "# print\n",
    "print(\"parse:\")\n",
    "print(\"is_graphic:\", is_graphic)\n",
    "print(\"cuda_num:\", cuda_num)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Display the number of available GPUs\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "    # Display the name of each GPU\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:\" + str(cuda_num) \n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.dataset)\n",
    "df = shuffle(df)\n",
    "\n",
    "df_test = df.iloc[0:3452]\n",
    "df_val = df.iloc[3452:7452]\n",
    "df_train = df.iloc[7452:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glovemgr = GloveMgr(\"./data/glove.6B/glove.6B.300d.txt\", vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs_sent = pd.read_json(\"data/nyt50_sent_tfidf.json\")\n",
    "tfidfs_sent = tfidfs_sent[\"tfidf\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs_dataset = json.load(open(\"./data/nyt50_dataset_tfidf.json\"))\n",
    "tfidfs_dataset_sorted = sorted(tfidfs_dataset, key=tfidfs_dataset.get)\n",
    "word_blacklist = set(tfidfs_dataset_sorted[:int(0.1*len(tfidfs_dataset_sorted))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_graph_dataset(df=df_train, tfidfs_sent=tfidfs_sent, glovemgr=glovemgr, word_blacklist = word_blacklist, doc_column_name=\"docs\", labels_column_name=\"labels\", is_sep_n=False, remove_stop_word = False, stemming=False, trunc_sent=-1, padding_sent=-1, trunc_doc=50)\n",
    "val_dataset = create_graph_dataset(df=df_val, tfidfs_sent=tfidfs_sent, glovemgr=glovemgr, word_blacklist = word_blacklist, doc_column_name=\"docs\", labels_column_name=\"labels\", is_sep_n=False, remove_stop_word = False, stemming=False, trunc_sent=-1, padding_sent=-1, trunc_doc=50)\n",
    "test_dataset = create_graph_dataset(df=df_test, tfidfs_sent=tfidfs_sent, glovemgr=glovemgr, word_blacklist = word_blacklist, doc_column_name=\"docs\", labels_column_name=\"labels\", is_sep_n=False, remove_stop_word = False, stemming=False, trunc_sent=-1, padding_sent=-1, trunc_doc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeterSUMGraph(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(HeterSUMGraph, self).__init__()\n",
    "    self.fc = torch.nn.Linear(in_features=1,out_features=1) # delete that\n",
    "    # TODO\n",
    "\n",
    "  def forward(self, data, nb_sent):# In the real implémentation remove nb_sent\n",
    "    # TODO\n",
    "    return [1 for _ in range(len(nb_sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeterSUMGraph().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoints_folder):\n",
    "  os.makedirs(checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?batch/s]/home/rsaid/anaconda3/lib/python3.9/site-packages/torch_geometric/data/storage.py:280: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x', 'edge_index', 'edge_attr', 'undirected'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n",
      "Epoch 100: 100%|██████████| 18/18 [00:00<00:00, 188.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training duration = 0.0984644889831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arr_train_loss = []\n",
    "arr_val_loss = []\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    nb_batch_train = 0\n",
    "    total_train_loss = 0\n",
    "    \n",
    "with tqdm(train_loader, unit=\"batch\", total=len(train_loader)) as tepoch:\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "        # TODO\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
